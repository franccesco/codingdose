<!DOCTYPE html>
<html>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="flattr:id" content="jj5n1v">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="A quick recap of the last post:  First we requested content using requests library and parsed the response’s contents using BeautifulSoup library. We learned that we can manipulate HTML tags, get its">
<meta property="og:type" content="article">
<meta property="og:title" content="Scraping Web Data With Requests and Beautifulsoup [Part 2]">
<meta property="og:url" content="http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/index.html">
<meta property="og:site_name" content="CodingDose()">
<meta property="og:description" content="A quick recap of the last post:  First we requested content using requests library and parsed the response’s contents using BeautifulSoup library. We learned that we can manipulate HTML tags, get its">
<meta property="og:image" content="http://codingdose.info/assets/images/bs4_scraping/pagination.png">
<meta property="article:published_time" content="2018-03-08T03:55:52.000Z">
<meta property="article:modified_time" content="2020-10-07T04:23:15.861Z">
<meta property="article:author" content="Franccesco Orozco">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://codingdose.info/assets/images/bs4_scraping/pagination.png">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>Scraping Web Data With Requests and Beautifulsoup [Part 2]</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- rss -->
    
    
    <!-- adsense -->
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-1481923801760340",
        enable_page_level_ads: true
      });
    </script>
    <script async defer data-website-id="022546b7-3b27-46f7-9864-a866afde723b" src="https://umami.onrender.com/umami.js"></script>
<meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="CodingDose()" type="application/atom+xml">
</head>

<body class="max-width mx-auto px3">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="https://github.com/franccesco" target="_blank" rel="noopener">Projects</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2018/03/09/get-a-download-size-with-Requests/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon umami--click--share-fb" href="http://www.facebook.com/sharer.php?u=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/" target="_blank" rel="noopener"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-twitter" href="https://twitter.com/share?url=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/&text=Scraping Web Data With Requests and Beautifulsoup [Part 2]" target="_blank" rel="noopener"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-lnkdn" href="http://www.linkedin.com/shareArticle?url=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/&title=Scraping Web Data With Requests and Beautifulsoup [Part 2]" target="_blank" rel="noopener"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-pinterest" href="https://pinterest.com/pin/create/bookmarklet/?url=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/&is_video=false&description=Scraping Web Data With Requests and Beautifulsoup [Part 2]" target="_blank" rel="noopener"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-mail" href="mailto:?subject=Scraping Web Data With Requests and Beautifulsoup [Part 2]&body=Check out this article: http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-pocket" href="https://getpocket.com/save?url=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/&title=Scraping Web Data With Requests and Beautifulsoup [Part 2]" target="_blank" rel="noopener"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-reddit" href="http://reddit.com/submit?url=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/&title=Scraping Web Data With Requests and Beautifulsoup [Part 2]" target="_blank" rel="noopener"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-stumble" href="http://www.stumbleupon.com/submit?url=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/&title=Scraping Web Data With Requests and Beautifulsoup [Part 2]" target="_blank" rel="noopener"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-digg" href="http://digg.com/submit?url=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/&title=Scraping Web Data With Requests and Beautifulsoup [Part 2]" target="_blank" rel="noopener"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-tumblr" href="http://www.tumblr.com/share/link?url=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/&name=Scraping Web Data With Requests and Beautifulsoup [Part 2]&description=" target="_blank" rel="noopener"><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Looping-over-pages"><span class="toc-number">1.</span> <span class="toc-text">Looping over pages</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Finding-our-the-number-of-pages"><span class="toc-number">2.</span> <span class="toc-text">Finding our the number of pages</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index my4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Scraping Web Data With Requests and Beautifulsoup [Part 2]
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Franccesco Orozco</span>
      </span>
      
    <div class="postdate">
        <time datetime="2018-03-08T03:55:52.000Z" itemprop="datePublished">2018-03-07</time>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/python/" rel="tag">python</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <p>A quick recap of the last post:</p>
<ul>
<li>First we requested content using <code>requests</code> library and parsed the response’s contents using BeautifulSoup library.</li>
<li>We learned that we can manipulate HTML tags, get its contents and attributes (like <code>href</code> from an <code>a</code> tag).</li>
<li>We found that the <em>Class</em> <code>post-list</code> is holding an unordered list containing the website’s post titles and links so we proceeded to get the <code>a</code> tag’s content on each list item as well as their <code>href</code> attribute.</li>
<li>We also store that data into a dictionary in a <code>{post_title: post_link}</code> format to be able to iterate over them and reuse them when needed.</li>
</ul>
<p>Now we only have one problem left, and it is <strong><em>pagination</em></strong>. Now as you can see, this is our current source file:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># requesting index page</span></span><br><span class="line">base_url = requests.get(<span class="string">'https://codingdose.info'</span>)</span><br><span class="line">url_contents = BeautifulSoup(base_url.text, <span class="string">'html.parser'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># filter post-list tag</span></span><br><span class="line">post_list = url_contents.find(class_=<span class="string">'post-list'</span>)</span><br><span class="line">post_items = post_list.find_all(<span class="string">'a'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># hold attributes in a dictionary</span></span><br><span class="line">post_dict = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> post <span class="keyword">in</span> post_items:</span><br><span class="line">    post_title = post.string</span><br><span class="line">    post_link = base_url.url + post.get(<span class="string">'href'</span>)</span><br><span class="line">    post_dict[post_title] = post_link</span><br><span class="line"></span><br><span class="line"><span class="comment"># iterate our dictionary</span></span><br><span class="line"><span class="keyword">for</span> title, link <span class="keyword">in</span> post_dict.items():</span><br><span class="line">    print(<span class="string">'&#123;&#125;: &#123;&#125;'</span>.format(title, link))</span><br></pre></td></tr></table></figure>

<p>When we execute our file it gives every post title and link from the main page:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> pipenv run python extract_links.py</span></span><br><span class="line">Scraping Web Data With Requests and Beautifulsoup [Part 1]: https://codingdose.info//2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/</span><br><span class="line">How to Send a Tweet With Python Using Tweepy: https://codingdose.info//2018/03/01/</span><br><span class="line">-- SNIP --</span><br><span class="line">Migrate From Ghost Blog to Jekyll: https://codingdose.info//2018/02/19/migrate-from-ghost-blog-to-jekyll/</span><br></pre></td></tr></table></figure>

<p>The thing is, the first post from this web page is <strong><em><a href="/2018/02/18/Hello-all/">Hello All!</a></em></strong> and not <strong><em><a href="/2018/02/19/migrate-from-ghost-blog-to-jekyll/">Migrate From blabla to blabla</a></em></strong>, and chances are that (hopefully) this blog is updated regularly and you’re not even getting the same results! So how do we get to page 2, 3, 4, and so on?</p>
<h2 id="Looping-over-pages"><a href="#Looping-over-pages" class="headerlink" title="Looping over pages"></a>Looping over pages</h2><p>Most blogs have <code>/page/1</code> or <code>/index.php?page=1</code> or any kind of pagination mechanism to show you more content in an ordered manner. If we wanted to iterate over pages we would first <em>request</em> <strong>/page/1</strong>, and then <strong>/page/2</strong> and so on.</p>
<p>But there’s a catch: <em>This site doesn’t have page 1.</em> It has <code>/page/2</code> in its URL (<code>https://codingdose.info/page/2/</code>) but page 1 it’s the <em>Index</em> page (<code>https://codingdose.info/</code>). But let’s not get ahead ourselves now, we’re going to get through this bit by bit.</p>
<h2 id="Finding-our-the-number-of-pages"><a href="#Finding-our-the-number-of-pages" class="headerlink" title="Finding our the number of pages"></a>Finding our the number of pages</h2><p>If we want to iterate over a number of pages, we first have to know how many pages there are in this little blog. If we go to the main page and scroll down we can see the number of pages in this blog: <em>Page 1 of X</em></p>
<p>If we inspect the string with the developer tools in our browser (Remember: <code>CTRL+SHIFT+C</code>) we find out that the string <em>Page 1 of X</em> is under the class <strong>page-number</strong></p>
<p><img src="/assets/images/bs4_scraping/pagination.png" alt="Inspection Tool"></p>
<p>Use the last number of this string to use it as the total pages this blog has and iterate over the total of those pages. At the time of writing, there are only 2 pages on this blog, so we are going to extract that number and convert it to a <em>Integer</em>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># requesting index page</span></span><br><span class="line">base_url = requests.get(<span class="string">'https://codingdose.info'</span>)</span><br><span class="line">url_contents = BeautifulSoup(base_url.text, <span class="string">'html.parser'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># filter post-list tag</span></span><br><span class="line">post_list = url_contents.find(class_=<span class="string">'post-list'</span>)</span><br><span class="line">post_items = post_list.find_all(<span class="string">'a'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># hold attributes in a dictionary</span></span><br><span class="line">post_dict = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># get the total number of pages</span></span><br><span class="line">class_pages = url_contents.find(class_=<span class="string">'page-number'</span>)</span><br><span class="line">pages_found = class_pages.get_text()</span><br><span class="line">total_pages = int(pages_found[<span class="number">-1</span>])</span><br><span class="line">print(<span class="string">'Total Pages Found: '</span> + str(total_pages))</span><br><span class="line">-- SNIP --</span><br></pre></td></tr></table></figure>

<p>What we are doing here is filtering the class <code>page-number</code> to narrow our search and extract the text that it holds with <code>.get_text()</code> to store <em>‘Page 1 of X’</em> in the variable <code>total_pages</code>, now we <em>slice</em> the last character of this string which is ‘2’ with <code>[-1]</code>. Now that we have the total number of pages we convert the string into an <em>integer</em> to be able to iterate over the pages.</p>
<p>But how we deal with the problem that I have no <code>/page/1</code>? Well, we will first extract the contents from the index page and <em>then</em> we will start iterating over the pages starting from page <strong>number 2</strong>. Remember that this is very unlikely to happen in most blogging systems but programming is all about problem solving, right?</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">base_url = requests.get(<span class="string">'https://codingdose.info'</span>)</span><br><span class="line">url_contents = BeautifulSoup(base_url.text, <span class="string">'html.parser'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># get the total number of pages</span></span><br><span class="line">class_pages = url_contents.find(class_=<span class="string">'page-number'</span>)</span><br><span class="line">pages_found = class_pages.get_text()</span><br><span class="line">total_pages = int(pages_found[<span class="number">-1</span>])</span><br><span class="line">print(<span class="string">'Total Pages: '</span> + str(total_pages))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">1</span>, total_pages + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">if</span> page == <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># requesting index page (page 1)</span></span><br><span class="line">        base_url = requests.get(<span class="string">'https://codingdose.info'</span>)</span><br><span class="line">    <span class="keyword">elif</span> page &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># after requesting index page, go directly to page 2/3/4...</span></span><br><span class="line">        base_url = requests.get(</span><br><span class="line">            <span class="string">'https://codingdose.info/page/&#123;&#125;/'</span>.format(page))</span><br><span class="line"></span><br><span class="line">    url_contents = BeautifulSoup(base_url.text, <span class="string">'html.parser'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># filter post-list tag</span></span><br><span class="line">    post_list = url_contents.find(class_=<span class="string">'post-list'</span>)</span><br><span class="line">    post_items = post_list.find_all(<span class="string">'a'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># hold attributes in a dictionary</span></span><br><span class="line">    post_dict = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> post <span class="keyword">in</span> post_items:</span><br><span class="line">        post_title = post.string</span><br><span class="line">        post_link = base_url.url + post.get(<span class="string">'href'</span>)</span><br><span class="line">        post_dict[post_title] = post_link</span><br><span class="line"></span><br><span class="line">    <span class="comment"># iterate our dictionary</span></span><br><span class="line">    <span class="keyword">for</span> title, link <span class="keyword">in</span> post_dict.items():</span><br><span class="line">        print(<span class="string">'&#123;&#125;: &#123;&#125;'</span>.format(title, link))</span><br></pre></td></tr></table></figure>

<p>Now, there are a number of changes that we have to take into consideration, first we enclosed most of our code in a <code>for</code> control flow using our <code>total_pages</code> Integer as a guide, if you look closely we can see a <code>+ 1</code> at the end of the <code>for</code> line, why is this? Remember that when you are looping with a range of numbers (let’s say from 0 to 9) in a <code>for</code> loop the control flow will stop at <strong>8</strong>, not <strong>9</strong>. This is because the <code>for</code> loop is <em>exclusive</em> not <em>inclusive</em> when looping over numbers, in this case, if we want the <code>for</code> loop to stop at <strong>2</strong> (inclusively, which is our current number of pages) we will have to add a number to our range.</p>
<p>If we are currently on <em>Page 1</em>, our base URL will be <em>‘<a href="https://codingdose.info&/#39;" target="_blank" rel="noopener">https://codingdose.info&#39;</a></em>, and if we are on <em>Page 2</em> then our base URL is going to be <em>‘<a href="https://codingdose.info/page/2/&#39;">https://codingdose.info/page/2/&#39;</a></em>, and so on.</p>
<p>Currently our code it’s starting to <a href="https://en.wikipedia.org/wiki/Code_smell" target="_blank" rel="noopener"><em>smell</em></a>, it needs to be refactored to prevent duplication and it could be a lot faster if we integrate concurrency and handle threads, but I will leave that to you, because this is <em>by far</em> not perfect… and it’s getting late here. I’ll end this post here and if you happen to clean the code and come up with a better idea then let me know in the comments bellow, thanks for reading.</p>

  </div>
</article>



    </div>
    
      <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="https://github.com/franccesco" target="_blank" rel="noopener">Projects</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Looping-over-pages"><span class="toc-number">1.</span> <span class="toc-text">Looping over pages</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Finding-our-the-number-of-pages"><span class="toc-number">2.</span> <span class="toc-text">Finding our the number of pages</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon umami--click--share-fb" href="http://www.facebook.com/sharer.php?u=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/" target="_blank" rel="noopener"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-twitter" href="https://twitter.com/share?url=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/&text=Scraping Web Data With Requests and Beautifulsoup [Part 2]" target="_blank" rel="noopener"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-lnkdn" href="http://www.linkedin.com/shareArticle?url=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/&title=Scraping Web Data With Requests and Beautifulsoup [Part 2]" target="_blank" rel="noopener"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-pinterest" href="https://pinterest.com/pin/create/bookmarklet/?url=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/&is_video=false&description=Scraping Web Data With Requests and Beautifulsoup [Part 2]" target="_blank" rel="noopener"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-mail" href="mailto:?subject=Scraping Web Data With Requests and Beautifulsoup [Part 2]&body=Check out this article: http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-pocket" href="https://getpocket.com/save?url=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/&title=Scraping Web Data With Requests and Beautifulsoup [Part 2]" target="_blank" rel="noopener"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-reddit" href="http://reddit.com/submit?url=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/&title=Scraping Web Data With Requests and Beautifulsoup [Part 2]" target="_blank" rel="noopener"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-stumble" href="http://www.stumbleupon.com/submit?url=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/&title=Scraping Web Data With Requests and Beautifulsoup [Part 2]" target="_blank" rel="noopener"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-digg" href="http://digg.com/submit?url=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/&title=Scraping Web Data With Requests and Beautifulsoup [Part 2]" target="_blank" rel="noopener"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-tumblr" href="http://www.tumblr.com/share/link?url=http://codingdose.info/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/&name=Scraping Web Data With Requests and Beautifulsoup [Part 2]&description=" target="_blank" rel="noopener"><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

    
    <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2020 Franccesco Orozco
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="https://github.com/franccesco" target="_blank" rel="noopener">Projects</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

</body>
</html>
<!-- styles -->

<link rel="stylesheet" href="/lib/font-awesome/css/fontawesome-all.min.css">


<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">


<!-- jquery -->

<script src="/lib/jquery/jquery.min.js"></script>


<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-114371181-1', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Disqus Comments -->


