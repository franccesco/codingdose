<!DOCTYPE html>
<html>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="Scraping web data is essential if we want to spider web pages for whatever reasons we have, maybe storing posts information (in my case) or monitor a web page, crawl data, etc. We are going to see how">
<meta property="og:type" content="article">
<meta property="og:title" content="Scraping Web Data With Requests and Beautifulsoup [Part 1]">
<meta property="og:url" content="http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/index.html">
<meta property="og:site_name" content="CodingDose()">
<meta property="og:description" content="Scraping web data is essential if we want to spider web pages for whatever reasons we have, maybe storing posts information (in my case) or monitor a web page, crawl data, etc. We are going to see how">
<meta property="og:image" content="http://codingdose.info/assets/images/bs4_scraping/inspection_tool.png">
<meta property="og:image" content="http://codingdose.info/assets/images/bs4_scraping/source_code.png">
<meta property="article:published_time" content="2018-03-05T23:02:37.000Z">
<meta property="article:modified_time" content="2020-10-07T04:23:15.861Z">
<meta property="article:author" content="Franccesco Orozco">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://codingdose.info/assets/images/bs4_scraping/inspection_tool.png">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>Scraping Web Data With Requests and Beautifulsoup [Part 1]</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
      
<link rel="stylesheet" href="/css/rtl.css">

    
    <!-- rss -->
    
    
<meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="CodingDose()" type="application/atom+xml">
</head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="https://github.com/franccesco" target="_blank" rel="noopener">GitHub</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2018/03/07/scraping-web-data-with-requests-and-beautifulsoup-part-2/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2018/03/01/How-to-send-a-tweet-with-Python-using-Tweepy/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon umami--click--share-fb" href="http://www.facebook.com/sharer.php?u=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/" target="_blank" rel="noopener"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-twitter" href="https://twitter.com/share?url=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&text=Scraping Web Data With Requests and Beautifulsoup [Part 1]" target="_blank" rel="noopener"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-linkedin" href="http://www.linkedin.com/shareArticle?url=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&title=Scraping Web Data With Requests and Beautifulsoup [Part 1]" target="_blank" rel="noopener"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-pinterest" href="https://pinterest.com/pin/create/bookmarklet/?url=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&is_video=false&description=Scraping Web Data With Requests and Beautifulsoup [Part 1]" target="_blank" rel="noopener"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-mail" href="mailto:?subject=Scraping Web Data With Requests and Beautifulsoup [Part 1]&body=Check out this article: http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-pocket" href="https://getpocket.com/save?url=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&title=Scraping Web Data With Requests and Beautifulsoup [Part 1]" target="_blank" rel="noopener"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-reddit" href="http://reddit.com/submit?url=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&title=Scraping Web Data With Requests and Beautifulsoup [Part 1]" target="_blank" rel="noopener"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-stumbleupon" href="http://www.stumbleupon.com/submit?url=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&title=Scraping Web Data With Requests and Beautifulsoup [Part 1]" target="_blank" rel="noopener"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-digg" href="http://digg.com/submit?url=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&title=Scraping Web Data With Requests and Beautifulsoup [Part 1]" target="_blank" rel="noopener"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-tumblr" href="http://www.tumblr.com/share/link?url=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&name=Scraping Web Data With Requests and Beautifulsoup [Part 1]&description=" target="_blank" rel="noopener"><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-ynews" href="https://news.ycombinator.com/submitlink?u=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&t=Scraping Web Data With Requests and Beautifulsoup [Part 1]" target="_blank" rel="noopener"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#What-are-we-going-to-do"><span class="toc-number">1.</span> <span class="toc-text">What are we going to do?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BeautifulSoup-and-Requests-Installation"><span class="toc-number">2.</span> <span class="toc-text">BeautifulSoup and Requests Installation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Requesting-Site-Data-with-GET-method"><span class="toc-number">3.</span> <span class="toc-text">Requesting Site Data with GET method</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Parsing-HTML"><span class="toc-number">4.</span> <span class="toc-text">Parsing HTML</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Extracting-all-posts-titles-and-links"><span class="toc-number">5.</span> <span class="toc-text">Extracting all posts titles and links</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Scraping Web Data With Requests and Beautifulsoup [Part 1]
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Franccesco Orozco</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2018-03-05T23:02:37.000Z" itemprop="datePublished">2018-03-05</time>
        
        (Updated: <time datetime="2020-10-07T04:23:15.861Z" itemprop="dateModified">2020-10-06</time>)
        
      
    </div>


      

      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/python/" rel="tag">python</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <p>Scraping web data is essential if we want to spider web pages for whatever reasons we have, maybe storing posts information (in my case) or monitor a web page, crawl data, etc.</p>
<p>We are going to see how to handle html data with <a href="https://www.crummy.com/software/BeautifulSoup/" target="_blank" rel="noopener">BeautifulSoup</a> and <a href="http://docs.python-requests.org/en/master/" target="_blank" rel="noopener">Requests</a> using this site as an example.</p>
<h2 id="What-are-we-going-to-do"><a href="#What-are-we-going-to-do" class="headerlink" title="What are we going to do?"></a>What are we going to do?</h2><ul>
<li>Make a <code>GET</code> request with the <code>requests</code> library to obtain the web page contents</li>
<li>Parse those contents into HTML so we can analyze and manipulate data using the powerful <code>BeautifulSoup</code></li>
<li>Learn how to deal with pagination [in part 2]</li>
</ul>
<h2 id="BeautifulSoup-and-Requests-Installation"><a href="#BeautifulSoup-and-Requests-Installation" class="headerlink" title="BeautifulSoup and Requests Installation"></a>BeautifulSoup and Requests Installation</h2><p>As usual using <code>pipenv</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pipenv install bs4 requests</span><br></pre></td></tr></table></figure>

<h2 id="Requesting-Site-Data-with-GET-method"><a href="#Requesting-Site-Data-with-GET-method" class="headerlink" title="Requesting Site Data with GET method"></a>Requesting Site Data with GET method</h2><p>Using this site as an example, we first have to request the site data before we parse it in HTML</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># requesting index page</span></span><br><span class="line">base_url = requests.get(<span class="string">'https://codingdose.info'</span>)</span><br></pre></td></tr></table></figure>

<p>This way we have stored our <code>GET</code> response into base_url, we can analyze the response code with <code>base_url.status_code</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>base_url.status_code</span><br><span class="line"><span class="number">200</span></span><br></pre></td></tr></table></figure>
<p>A <code>200</code> response code means that our request was successful.</p>
<p>You can find more information on <code>HTTP</code> statuses on <a href="https://httpstatuses.com/" target="_blank" rel="noopener">httpstatuses.com</a>, keep this site as a reference guide when working with web data such as http statuses and requests.</p>
<h2 id="Parsing-HTML"><a href="#Parsing-HTML" class="headerlink" title="Parsing HTML"></a>Parsing HTML</h2><p>Now with <code>requests</code> we can parse our HTML data with <code>requests</code> using <code>base_url.text</code> but it doesn’t offer the plethora of information and benefits that BeautifulSoup can offer. Let’s import BeautifulSoup and find out what can we do with it.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># requesting index page</span></span><br><span class="line">base_url = requests.get(<span class="string">'https://codingdose.info'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># parse html data</span></span><br><span class="line">url_contents = BeautifulSoup(base_url.text, <span class="string">'html.parser'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># printing a pretty version of our HTML data</span></span><br><span class="line">print(url_contents.prettify())</span><br></pre></td></tr></table></figure>

<p>We can see that our output is a prettified version of our HTML requests with proper spacing and new lines</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- SNIP --&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">title</span>&gt;</span></span><br><span class="line">    CodingDose()</span><br><span class="line">   <span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">   <span class="comment">&lt;!-- styles --&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">link</span> <span class="attr">href</span>=<span class="string">"/css/style.css"</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span>/&gt;</span></span><br><span class="line">   <span class="comment">&lt;!-- rss --&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">link</span> <span class="attr">href</span>=<span class="string">"/atom.xml"</span> <span class="attr">rel</span>=<span class="string">"alternate"</span> <span class="attr">title</span>=<span class="string">"CodingDose()"</span> <span class="attr">type</span>=<span class="string">"application/atom+xml"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">link</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">meta</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- SNIP --&gt;</span></span><br></pre></td></tr></table></figure>

<p>Now this is a lot of data, what if we only want to extract the title?</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>url_contents.title</span><br><span class="line">&lt;title&gt;CodingDose()&lt;/title&gt;</span><br></pre></td></tr></table></figure>

<p>Ok, what if we want to strip the tags?</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>url_contents.title.string</span><br><span class="line"><span class="string">'CodingDose()'</span></span><br></pre></td></tr></table></figure>

<p>What about if we want all the the <code>&lt;p&gt;</code> tags?</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> p <span class="keyword">in</span> url_contents.find_all(<span class="string">'p'</span>):</span><br><span class="line"><span class="meta">... </span>   print(p.string)</span><br></pre></td></tr></table></figure>

<p>You can find all the documentation and methods in the <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank" rel="noopener">BS4 docs</a></p>
<h2 id="Extracting-all-posts-titles-and-links"><a href="#Extracting-all-posts-titles-and-links" class="headerlink" title="Extracting all posts titles and links"></a>Extracting all posts titles and links</h2><p>Now, as an example, we are going to scrape this site and extract all posts titles and links, and store them in a dictionary so we can loop around them, store them or do whatever we want with them.</p>
<p>There’s a lot of links in this site, so how can we identify only the posts titles and links? We can use the browser inspection tool to identify the <em>Class</em> that holds our links pressing <code>CTRL + SHIFT + C</code> and clicking the first post link to inspect information about it:</p>
<p><img src="/assets/images/bs4_scraping/inspection_tool.png" alt="Inspection tool"></p>
<p>Now we see how the link and title is handled in the HTML source code displayed in the Inspection Tool:</p>
<p><img src="/assets/images/bs4_scraping/source_code.png" alt="Source Code"></p>
<p>As we can see, our post’s link and title is inside a <code>&lt;li&gt;</code> (<strong>L</strong>ist <strong>I</strong>tem) tag which is inside an <code>&lt;ul&gt;</code> (<strong>U</strong>nordered <strong>L</strong>ist) tag which belongs to the class <code>post-list</code>, now we can narrow our search using BeautifulSoup and the method <code>.find_all(tag)</code> to identify links and strings that only belongs to this class</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># requesting index page</span></span><br><span class="line">base_url = requests.get(<span class="string">'https://codingdose.info'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># parse html data</span></span><br><span class="line">url_contents = BeautifulSoup(base_url.text, <span class="string">'html.parser'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># extract contents from class post-list</span></span><br><span class="line">post_list = url_contents.find(class_=<span class="string">'post-list'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># filter and print link tags ('a') from previous list</span></span><br><span class="line">post_items = post_list.find_all(<span class="string">'a'</span>)</span><br><span class="line">print(post_items)</span><br></pre></td></tr></table></figure>

<p>Now we have a list including all links and titles from our <code>post-list</code> class but to be honest, it’s quite a mess, so let’s order our posts into a <code>{title}: {link}</code> format using the method <code>.get</code> from each item in our list which extracts the attribute data from our tags, this way if we have:</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">""</span> <span class="attr">href</span>=<span class="string">"/2018/03/01/How-to-send-a-tweet-with-Python-using-Tweepy/"</span>&gt;</span>How to Send a Tweet With Python Using Tweepy<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>We can use the method <code>.get(href)</code> to extract the attribute content (<em>/2018/03/01/How-to-send-a-tweet-with-Python-using-Tweepy/</em>) and of course we would have to attach a our base url to each <code>href</code> attribute so it displays a complete URL:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># requesting index page</span></span><br><span class="line">base_url = requests.get(<span class="string">'https://codingdose.info'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># parse html data</span></span><br><span class="line">url_contents = BeautifulSoup(base_url.text, <span class="string">'html.parser'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># extract contents from class post-list</span></span><br><span class="line">post_list = url_contents.find(class_=<span class="string">'post-list'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># filter and print link tags ('a') from previous list</span></span><br><span class="line">post_items = post_list.find_all(<span class="string">'a'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># extracting post item and post link from 'post_items'</span></span><br><span class="line"><span class="keyword">for</span> post <span class="keyword">in</span> post_items:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># extract title with '.string' method</span></span><br><span class="line">    post_title = post.string</span><br><span class="line"></span><br><span class="line">    <span class="comment"># attach 'base_url' url to each 'href' attribute content</span></span><br><span class="line">    post_link = base_url.url + post.get(<span class="string">'href'</span>)</span><br><span class="line">    print(<span class="string">'&#123;&#125;: &#123;&#125;'</span>.format(post_title, post_link))</span><br></pre></td></tr></table></figure>

<p>Now we have a formatted list with our titles and links, but we should store that information in a dictionary so we can reuse it later, alright? Let’s add a dictionary holding our values in the following format:<br><code>post_dict[post_title] = post_link</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="comment"># requesting index page</span></span><br><span class="line">base_url = requests.get(<span class="string">'https://codingdose.info'</span>)</span><br><span class="line">url_contents = BeautifulSoup(base_url.text, <span class="string">'html.parser'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># filter post-list tag</span></span><br><span class="line">post_list = url_contents.find(class_=<span class="string">'post-list'</span>)</span><br><span class="line">post_items = post_list.find_all(<span class="string">'a'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># hold attributes in a dictionary</span></span><br><span class="line">post_dict = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> post <span class="keyword">in</span> post_items:</span><br><span class="line">    post_title = post.string</span><br><span class="line">    post_link = base_url.url + post.get(<span class="string">'href'</span>)</span><br><span class="line">    post_dict[post_title] = post_link</span><br><span class="line"></span><br><span class="line"><span class="comment"># iterate our dictionary</span></span><br><span class="line"><span class="keyword">for</span> title, link <span class="keyword">in</span> post_dict.items():</span><br><span class="line">    print(<span class="string">'&#123;&#125;: &#123;&#125;'</span>.format(title, link))</span><br></pre></td></tr></table></figure>

<p>Now that our values (title and link) are attached to our dictionary, we can reuse them in our code, maybe to create a database with posts and links? Share them to twitter? Crawling? Whatever we want to do with them, we can do it easily if we hold our values in a dictionary.</p>
<p>We have only one problem left… <em><strong>pagination</strong></em>. You see, we only have the links in the index page, how can we make our script go to the second page, and the third one and so on to extract the titles and links on those pages? We’ll see this in the second part of this post. <em>See ya.</em></p>

  </div>
</article>

    <div class="blog-post-comments">
        <div id="disqus_thread">
            <noscript>Please enable JavaScript to view the comments.</noscript>
        </div>
    </div>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="https://github.com/franccesco" target="_blank" rel="noopener">GitHub</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#What-are-we-going-to-do"><span class="toc-number">1.</span> <span class="toc-text">What are we going to do?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BeautifulSoup-and-Requests-Installation"><span class="toc-number">2.</span> <span class="toc-text">BeautifulSoup and Requests Installation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Requesting-Site-Data-with-GET-method"><span class="toc-number">3.</span> <span class="toc-text">Requesting Site Data with GET method</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Parsing-HTML"><span class="toc-number">4.</span> <span class="toc-text">Parsing HTML</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Extracting-all-posts-titles-and-links"><span class="toc-number">5.</span> <span class="toc-text">Extracting all posts titles and links</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon umami--click--share-fb" href="http://www.facebook.com/sharer.php?u=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/" target="_blank" rel="noopener"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-twitter" href="https://twitter.com/share?url=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&text=Scraping Web Data With Requests and Beautifulsoup [Part 1]" target="_blank" rel="noopener"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-linkedin" href="http://www.linkedin.com/shareArticle?url=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&title=Scraping Web Data With Requests and Beautifulsoup [Part 1]" target="_blank" rel="noopener"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-pinterest" href="https://pinterest.com/pin/create/bookmarklet/?url=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&is_video=false&description=Scraping Web Data With Requests and Beautifulsoup [Part 1]" target="_blank" rel="noopener"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-mail" href="mailto:?subject=Scraping Web Data With Requests and Beautifulsoup [Part 1]&body=Check out this article: http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-pocket" href="https://getpocket.com/save?url=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&title=Scraping Web Data With Requests and Beautifulsoup [Part 1]" target="_blank" rel="noopener"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-reddit" href="http://reddit.com/submit?url=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&title=Scraping Web Data With Requests and Beautifulsoup [Part 1]" target="_blank" rel="noopener"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-stumbleupon" href="http://www.stumbleupon.com/submit?url=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&title=Scraping Web Data With Requests and Beautifulsoup [Part 1]" target="_blank" rel="noopener"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-digg" href="http://digg.com/submit?url=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&title=Scraping Web Data With Requests and Beautifulsoup [Part 1]" target="_blank" rel="noopener"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-tumblr" href="http://www.tumblr.com/share/link?url=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&name=Scraping Web Data With Requests and Beautifulsoup [Part 1]&description=" target="_blank" rel="noopener"><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon umami--click--share-ynews" href="https://news.ycombinator.com/submitlink?u=http://codingdose.info/2018/03/05/scraping-web-data-with-requests-and-beautifulsoup/&t=Scraping Web Data With Requests and Beautifulsoup [Part 1]" target="_blank" rel="noopener"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2018-2020
    Franccesco Orozco
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="https://github.com/franccesco" target="_blank" rel="noopener">GitHub</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->

<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">


<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">


    <!-- jquery -->

<script src="/lib/jquery/jquery.min.js"></script>


<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>

<!-- clipboard -->

  
<script src="/lib/clipboard/clipboard.min.js"></script>

  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-114371181-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-114371181-1');
    </script>

<!-- Baidu Analytics -->

<!-- Umami Analytics -->

  <script async defer data-website-id="022546b7-3b27-46f7-9864-a866afde723b" src="https://umami.onrender.com/umami.js"></script>

<!-- Disqus Comments -->

    <script type="text/javascript">
        var disqus_shortname = 'codingdose';

        (function(){
            var dsq = document.createElement('script');
            dsq.type = 'text/javascript';
            dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        }());
    </script>


</body>
</html>
